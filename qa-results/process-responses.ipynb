{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from tempfile import TemporaryDirectory\n",
    "import gzip\n",
    "import struct\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_df = pd.read_csv(\"lung-pet-ct-responses.csv\", dtype=str, keep_default_na=False)\n",
    "qa_res_df = pd.read_csv(\"qa-results.csv\", dtype=str, keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qa_res_df.sort_values(\n",
    "#     by=[\n",
    "#         \"Reviewer\",\n",
    "#         \"Validation\",\n",
    "#         \"Collection\",\n",
    "#         \"PatientID\",\n",
    "#         \"StudyDate\",\n",
    "#         \"StudyDate_suffix\",\n",
    "#     ],\n",
    "#     inplace=True,\n",
    "# )\n",
    "# qa_res_df.to_csv(\"qa-results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_nrrd(fp):\n",
    "    with open(fp, \"rb\") as f:\n",
    "        return f.read(4) == b\"NRRD\"\n",
    "\n",
    "\n",
    "def is_nii_gz(fp):\n",
    "    with open(fp, \"rb\") as f:\n",
    "        try:\n",
    "            nii = gzip.open(fp).read()\n",
    "        except gzip.BadGzipFile:\n",
    "            return False\n",
    "        header_size = struct.unpack(\"<i\", nii[0:4])[0]\n",
    "        magic = nii[344:348]\n",
    "        return header_size == 348 and magic in (b\"n+1\\00\", b\"ni1+\\00\")\n",
    "\n",
    "\n",
    "def convert_gdrive_link(url):\n",
    "    file_id = url.split(\"id=\")[-1]\n",
    "    return f\"https://docs.google.com/uc?export=download&id={file_id}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_df.rename(\n",
    "    columns={\n",
    "        \"Please enter your name\": \"Reviewer\",\n",
    "        \"What is the patient name?\": \"PatientID\",\n",
    "        \"Was the AI predicted ROIs accurate?\": \"LikertScore\",\n",
    "        \"Do you have any comments about the AI predicted ROIs?\": \"CommentsAboutAISegmentation\",\n",
    "        \"Do you have any comments about the findings from the study scans?\": \"CommentsAboutScan\",\n",
    "        \"What is the study date folder?\": \"StudyDateFolder\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "resp_df.replace(\n",
    "    {\n",
    "        \"Strongly Agree - Use-as-is (i.e., clinically acceptable, and could be used for treatment without change)\": \"5\",\n",
    "        \"Agree - Minor edits that are not necessary. Stylistic differences, but not clinically important. The current segmentation is acceptable\": \"4\",\n",
    "        \"Neither agree nor disagree - Minor edits that are necessary. Minor edits are those that the review judges can be made in less time than starting from scratch or are expected to have minimal effect on treatment outcome\": \"3\",\n",
    "        \"Disagree - Major edits. This category indicates that the necessary edit is required to ensure correctness, and sufficiently significant that user would prefer to start from the scratch\": \"2\",\n",
    "        \"Strongly disagree - Unusable. This category indicates that the quality of the automatic annotations is so bad that they are unusable.\": \"1\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "resp_df.replace({\"Mariam Aboian\": \"rad1\", \"Tej Verma\": \"ne1\"}, inplace=True)\n",
    "\n",
    "# change studydate from m-d-y to yyyymmmdd\n",
    "# resp_df[\"StudyDate\"] = pd.to_datetime(df[\"StudyDate\"]).dt.strftime(\"%Y%m%d\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviewer ne1 has no duplicate scans reviewed\n",
      "Reviewer rad1 has no duplicate scans reviewed\n"
     ]
    }
   ],
   "source": [
    "reviewers = resp_df[\"Reviewer\"].unique()\n",
    "for reviewer in reviewers:\n",
    "    StudyDateFolders = resp_df[resp_df[\"Reviewer\"] == reviewer][\n",
    "        [\n",
    "            \"PatientID\",\n",
    "            \"StudyDateFolder\",\n",
    "        ]\n",
    "    ]\n",
    "    # check that there are no duplicates in StudyDateFolder\n",
    "    if len(StudyDateFolders) != len(StudyDateFolders.drop_duplicates()):\n",
    "        print(\"Reviewer {} has duplicate scans reviewed\".format(reviewer))\n",
    "        # print duplicates\n",
    "        print(StudyDateFolders[StudyDateFolders.duplicated()])\n",
    "    else:\n",
    "        print(\"Reviewer {} has no duplicate scans reviewed\".format(reviewer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in qa-results:\n",
    "for resp_i, resp_row in resp_df.iterrows():\n",
    "    if \"_\" in resp_row[\"StudyDateFolder\"]:\n",
    "        study_date, suffix = resp_row[\"StudyDateFolder\"].split(\"_\")\n",
    "    else:\n",
    "        study_date = resp_row[\"StudyDateFolder\"]\n",
    "        suffix = \"0\"\n",
    "    reader = resp_row[\"Reviewer\"]\n",
    "    pid = resp_row[\"PatientID\"]\n",
    "\n",
    "    # find the row to edit in qa_res_df\n",
    "    index_to_edit = None\n",
    "    qa_rows = qa_res_df[\n",
    "        (qa_res_df[\"Reviewer\"] == reader)\n",
    "        & (qa_res_df[\"PatientID\"] == pid)\n",
    "        & (qa_res_df[\"StudyDate\"] == study_date)\n",
    "        & (qa_res_df[\"StudyDate_suffix\"] == suffix)\n",
    "    ]\n",
    "    if len(qa_rows) == 1:\n",
    "        index_to_edit = qa_rows.index[0]\n",
    "    elif len(qa_rows) > 1:\n",
    "        raise RuntimeError(\"More than one row found for {}\".format(resp_row))\n",
    "    else:\n",
    "        # find blank row\n",
    "        qa_rows = qa_res_df[\n",
    "            (qa_res_df[\"Reviewer\"] == \"\")\n",
    "            & (qa_res_df[\"PatientID\"] == pid)\n",
    "            & (qa_res_df[\"StudyDate\"] == study_date)\n",
    "            & (qa_res_df[\"StudyDate_suffix\"] == suffix)\n",
    "        ]\n",
    "        if len(qa_rows) == 1:\n",
    "            index_to_edit = qa_rows.index[0]\n",
    "        elif len(qa_rows) > 1:\n",
    "            raise RuntimeError(\"More than one row found for {}\".format(resp_row))\n",
    "        else:\n",
    "            # copy minimum from other row\n",
    "            qa_rows = qa_res_df[\n",
    "                (qa_res_df[\"PatientID\"] == pid)\n",
    "                & (qa_res_df[\"StudyDate\"] == study_date)\n",
    "                & (qa_res_df[\"StudyDate_suffix\"] == suffix)\n",
    "            ]\n",
    "            if len(qa_rows) == 0:\n",
    "                raise RuntimeError(\"No rows found for {}\".format(resp_row))\n",
    "            else:\n",
    "                # raise RuntimeError(\"DEBUG BREAK: Copying row for {}\".format(resp_row))\n",
    "                row_to_copy = qa_rows.iloc[0]\n",
    "                # keep only the minimum columes\n",
    "                row_to_copy = row_to_copy[\n",
    "                    [\n",
    "                        \"Collection\",\n",
    "                        \"PatientID\",\n",
    "                        \"StudyInstanceUID\",\n",
    "                        \"PTSeriesInstanceUID\",\n",
    "                        \"CTSeriesInstanceUID\",\n",
    "                        # \"Segmentation\",\n",
    "                        \"StudyDate\",\n",
    "                        \"StudyDate_suffix\",\n",
    "                        \"Validation\",\n",
    "                        # \"LikertScore\",\n",
    "                        # \"CommentsAboutAISegmentation\",\n",
    "                        # \"CommentsAboutScan\",\n",
    "                        # \"CorrectedSegmentation\",\n",
    "                        \"AISegmentation\",\n",
    "                    ]\n",
    "                ]\n",
    "                # add to qa_res_df\n",
    "                qa_res_df = pd.concat(\n",
    "                    [qa_res_df, row_to_copy.to_frame().T], ignore_index=True\n",
    "                )\n",
    "                # get index of new row\n",
    "                index_to_edit = qa_res_df.index[-1]\n",
    "\n",
    "    # edit row\n",
    "    qa_res_df.loc[index_to_edit, \"Reviewer\"] = reader\n",
    "    qa_res_df.loc[index_to_edit, \"LikertScore\"] = resp_row[\"LikertScore\"]\n",
    "    qa_res_df.loc[index_to_edit, \"CommentsAboutAISegmentation\"] = resp_row[\n",
    "        \"CommentsAboutAISegmentation\"\n",
    "    ]\n",
    "    qa_res_df.loc[index_to_edit, \"CommentsAboutScan\"] = resp_row[\"CommentsAboutScan\"]\n",
    "\n",
    "    # download and save corrected segmentation\n",
    "    url = resp_row[\"Please upload your corrected segmentation file\"]\n",
    "    if url:\n",
    "        if qa_res_df.loc[index_to_edit, \"CorrectedSegmentation\"]:\n",
    "            continue\n",
    "            # raise RuntimeError(\"CorrectedSegmentation already exists\")\n",
    "\n",
    "        resp_filename = f\"{reader}_{pid}_{study_date}_{suffix}\"\n",
    "\n",
    "        # download\n",
    "        r = requests.get(convert_gdrive_link(url), allow_redirects=True)\n",
    "        with TemporaryDirectory() as tmpdir:\n",
    "            tmp_file = Path(tmpdir) / \"tmp\"\n",
    "            tmp_file.open(\"wb\").write(r.content)\n",
    "            if is_nrrd(tmp_file):\n",
    "                resp_filename += \".nrrd\"\n",
    "            elif is_nii_gz(tmp_file):\n",
    "                resp_filename += \".nii.gz\"\n",
    "            else:\n",
    "                raise RuntimeError(f\"Unknown file type for {resp_row}\")\n",
    "\n",
    "            resp_filepath = Path(\"qa-segmentations\") / resp_filename\n",
    "            resp_filepath.parent.mkdir(exist_ok=True, parents=True)\n",
    "            shutil.copy(tmp_file, resp_filepath)\n",
    "            qa_res_df.loc[index_to_edit, \"CorrectedSegmentation\"] = resp_filename\n",
    "            qa_res_df.to_csv(\"qa-results.csv\", index=False)  # checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save qa_res_df\n",
    "qa_res_df.sort_values(\n",
    "    by=[\n",
    "        \"Reviewer\",\n",
    "        \"Validation\",\n",
    "        \"Collection\",\n",
    "        \"PatientID\",\n",
    "        \"StudyDate\",\n",
    "        \"StudyDate_suffix\",\n",
    "    ],\n",
    "    inplace=True,\n",
    ")\n",
    "qa_res_df.to_csv(\"qa-results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
